'use client'

import { Order } from "@/shared/types/global";
import { ChatCompletionMessageParam, CreateMLCEngine, CreateWebWorkerMLCEngine, MLCEngine } from "@mlc-ai/web-llm";
/**
 * The WebLLM engine.
 */
let engine: MLCEngine | null = null;
/**
 * The progress of the WebLLM engine.
 */
export type InitProgress = { percentage: number; text?: string };
/**
 * Initialize the WebLLM engine.
 * @param modelId The model ID.
 * @param onProgress The progress callback.
 * @returns The engine.
 */
// export async function initWebLLM(
//   modelId = "Llama-3.1-8B-Instruct-q4f32_1-MLC",
//   onProgress?: (progress: InitProgress) => void
// ) {

//   engine = await CreateMLCEngine(modelId, {
//     initProgressCallback: (rep: any) => {
//       // rep은 버전에 따라 number 또는 객체( { progress: 0~1, text } )일 수 있음
//       const ratio = typeof rep === "number" 
//         ? rep 
//         : typeof rep?.progress === "number" 
//           ? rep.progress 
//           : 0;
//       const text = typeof rep === "object" 
//         ? rep.text 
//         : undefined;
//       onProgress?.({ percentage: Math.round(ratio * 100), text });
//     },
//   });
//   return engine!;
// }
export async function initWebLLM(
  modelId = "Llama-3.1-8B-Instruct-q4f32_1-MLC",
  onProgress?: (progress: InitProgress) => void
) {
  try {
    engine = new MLCEngine({
      initProgressCallback: (rep: any) => {
        // rep은 버전에 따라 number 또는 객체( { progress: 0~1, text } )일 수 있음
        const ratio = typeof rep === "number" 
          ? rep 
          : typeof rep?.progress === "number" 
            ? rep.progress 
            : 0;
        const text = typeof rep === "object" 
          ? rep.text 
          : undefined;
        onProgress?.({ percentage: Math.round(ratio * 100), text });
      },
    });
  } catch (e) {
    console.error(e);
    throw e;
  }
  return engine?.reload(modelId);
}
/**
 * Get the WebLLM engine.
 * @returns 
 */
export function getEngine() {
  if (!engine) throw new Error("WebLLM not initialized");
  return engine;
}

export async function cancelLoading() {
  console.log('cancelLoading-------', engine);
  await engine?.unload();   // 로딩/컴파일 중단
  engine = null;
}
// https://webllm.mlc.ai/docs/user/advanced_usage.html
// let worker: Worker | null = null;
// export function startLoadingInWorker(
//   modelId: string, 
//   onProgress:(progress: InitProgress) => void
// ) {
//   worker = new Worker(new URL("./mlc-worker.ts", import.meta.url), { type: "module" });
//   // If you need, you can catch the Promise and cancel it with worker.terminate()
//   return CreateWebWorkerMLCEngine(worker, modelId, { 
//     initProgressCallback: (rep: any) => {
//       // rep은 버전에 따라 number 또는 객체( { progress: 0~1, text } )일 수 있음
//       const ratio = typeof rep === "number" 
//         ? rep 
//         : typeof rep?.progress === "number" 
//           ? rep.progress 
//           : 0;
//       const text = typeof rep === "object" 
//         ? rep.text 
//         : undefined;
//       onProgress?.({ percentage: Math.round(ratio * 100), text });
//     },
//   });
// }
// export function cancelLoadingInWorker() {
//   worker?.terminate();   // 강제 종료
//   worker = null;
// }

/**
 * Make speech text with LLM.
 * The sentence is generated by LLM.
 */
export class WebLLM {
  async makeSpeechText(order: Order): Promise<string> {
    const n = order.orderNum;
    const messages:ChatCompletionMessageParam[] = [
      { role: "system", content: "You are a McDonald's AI assistant. User will give you the order number. You will call the order number. e.g. '123! 123! Your order is ready." },
      { role: "user", content: `${n}` },
    ]
    
    const reply = await engine?.chat.completions.create({ messages });
    console.log(reply?.choices[0].message);
    console.log(reply?.usage);

    const base = `${n}! ${n}! Your order is ready.`;
    return reply?.choices[0].message.content || base;
  }
}